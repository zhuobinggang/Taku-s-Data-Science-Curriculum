## TODO

- [ ] What do recurrent neural network gammars learn about syntax? (语法建模)

#### VAE

- [ ] 2017 Toward controlled generation of text.  (text style transfer) (Adversarial Loss)
- [ ] 2018 Disentangled representation learning for text style transfer. (text style transfer) 
- [ ] 2018 Style transfer in text: Exploration and evaluation. (text style transfer)
- [ ] 2018 Syntax-directed variational autoencoder for structured data. (impose context-free grammars (CFGs as hard constraints in the VAE decoder)
- [ ] 2018 A deep generative framework for paraphrase generation.
- [ ] 2018 Syntactic manipulation for generating more diverse and interesting texts.
- [ ] 2017 Grammar variational autoencoder.

## Done 

- Generating Sentences from Disentangled Syntactic and Semantic Spaces (居然是字节跳动的论文，主要是对潜在空间的z计算了一些辅助loss，以引入一些额外知识，老实说太复杂了我感觉应用前景不大)
