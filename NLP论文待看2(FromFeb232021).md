## TODO

- [ ] What do recurrent neural network gammars learn about syntax? (语法建模)
- [ ] On Unifying Deep Generative Models (统一生成模型) (No1的后续论文)
- [X] PIAGET’S STRUCTURALISM AND LINGUISTICS (Cool)

### VAE & GAN

#### CV
- [ ] 2018 20 Generative Adversarial Interpolative Autoencoding (GAIA) (线性插值，VAE和GAN的融合) 
- [ ] 2017 7578 CycleGAN
- [ ] 2018 1717 A Style-Based Generator Architecture for Generative Adversarial Networks (Style gan，正在做) (需要前置： Arbitrary Style Transfer)
- [ ] 2017 1084 Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization (STleGan 前置)
- [ ] 2016 8604 Unsupervised representation learning with deep convolutional generative adversarial networks (图片空间向量操作)

#### NLP
- [ ] 2018 89 Disentangled representation learning for text style transfer. (text style transfer) 
- [ ] 2018 254 Style transfer in text: Exploration and evaluation. (text style transfer)
- [ ] 2018 154 Syntax-directed variational autoencoder for structured data. (impose context-free grammars (CFGs as hard constraints in the VAE decoder)
- [ ] 2018 123 A deep generative framework for paraphrase generation.
- [ ] 2018 11 Syntactic manipulation for generating more diverse and interesting texts.
- [ ] 2017 374 Grammar variational autoencoder.

## Done 

- [X] #1 Generating Sentences from Disentangled Syntactic and Semantic Spaces (居然是字节跳动的论文，主要是对潜在空间的z计算了一些辅助loss，以引入一些额外知识，老实说太复杂了我感觉应用前景不大)
- [X] #2 2017 Toward controlled generation of text.  (text style transfer) (Adversarial Loss)
- [X] #3 2016 cite2572 InfoGan
  - [X] #3.1 Understanding Mutual Information and its Use in InfoGAN
