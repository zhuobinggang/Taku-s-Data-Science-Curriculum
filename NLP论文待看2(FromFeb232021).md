## TODO

- [ ] What do recurrent neural network gammars learn about syntax? (语法建模)
- [ ] On Unifying Deep Generative Models (统一生成模型) (No1的后续论文)

#### VAE & GAN


- [ ] 2018 Disentangled representation learning for text style transfer. (text style transfer) 
- [ ] 2018 Style transfer in text: Exploration and evaluation. (text style transfer)
- [ ] 2018 Syntax-directed variational autoencoder for structured data. (impose context-free grammars (CFGs as hard constraints in the VAE decoder)
- [ ] 2018 A deep generative framework for paraphrase generation.
- [ ] 2018 Syntactic manipulation for generating more diverse and interesting texts.
- [ ] 2017 Grammar variational autoencoder.
- [ ] 2018 Generative Adversarial Interpolative Autoencoding (GAIA) (线性插值，VAE和GAN的融合)
- [X] 2018 A Style-Based Generator Architecture for Generative Adversarial Networks (Style gan，正在做)

## Done 

1. Generating Sentences from Disentangled Syntactic and Semantic Spaces (居然是字节跳动的论文，主要是对潜在空间的z计算了一些辅助loss，以引入一些额外知识，老实说太复杂了我感觉应用前景不大)
2. 2017 Toward controlled generation of text.  (text style transfer) (Adversarial Loss)
